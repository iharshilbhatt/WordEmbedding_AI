# -*- coding: utf-8 -*-
"""WordEmbedding.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Sdst7ieSFSsQY525O72DpgMPsrXPECSX
"""

import math
from collections import Counter # finding the frequency count

"""Tokenize"""

def tokenize(document):
  return document.lower().split()

#TF calculations
def term_frequency_calculation(document):
  words_freq=Counter(tokenize(document))
  total_words=len(words_freq)
  tf={word: count/total_words for word,count in words_freq.items()}
  return tf

#now IDF
def calculate_idf(documents):
  total_docs=len(documents)
  total_words=set(word for doc in documents for word in tokenize(doc))
  idf={word:math.log(total_docs/sum(1 for doc in documents if word in tokenize(doc)))for word in total_words}
  return idf

def calculate_tfidf(tf, idf):
  tfidf={word:tf[word]*idf[word] for word in tf}
  return tfidf

documents=["I am learning artficial intelligenece","NLP is a part of artificial intelligence","artificial transplantation of organs are possible"]

idf=calculate_idf(documents)
tf_idfembedding=[]

for document in documents:
  tf=term_frequency_calculation(document)
  tf_idf=calculate_tfidf(tf,idf)
  tf_idfembedding.append(tf_idf)

import pandas as pd
tf_idfembed = pd.DataFrame(tf_idfembedding)

print(tf_idfembedding)

print(tf_idfembed)

#TextRank for keyword extraction
import spacy

pip install pytextrank

import pytextrank

nlp=spacy.load('en_core_web_sm')

nlp.add_pipe("textrank")

text=("In November 2022, during a joint press conference along with Russian foreign minister Sergey Lavrov, Jaishankar praised Russia as 'exceptionally steady' and 'time-tested' partner of India and advocated a return to dialogue and peace between Russia and Ukraine. In June 2023, the Associated Press (AP) reported that Jaishankar had announced that India will remain committed in its stance on not inviting Ukraine to the 2023 G20 summit that is to be held in New Delhi, India.")

doc=nlp(text)

for chunks in doc._.phrases:
  print(chunks.chunks) #in chunks shows how many time that words repeated

print(chunks.text)